{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "spark = SparkSession.builder.appName(\"YourAppName\")\\\n",
    "                .config(\"spark.driver.memory\", \"4g\")\\\n",
    "                .config(\"spark.executor.memory\", \"4g\")\\\n",
    "                .config(\"spark.driver.maxResultSize\", \"2g\")\\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pySparkSetup').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "train_id = spark.read.csv('datasets/ps-2/train_identity.csv', header=True, inferSchema=True)\n",
    "train_tr = spark.read.csv('datasets/ps-2/train_transaction.csv', header=True, inferSchema=True)\n",
    "test_id = spark.read.csv('datasets/ps-2/test_identity.csv', header=True, inferSchema=True)\n",
    "test_tr = spark.read.csv('datasets/ps-2/test_transaction.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Merge the DataFrames\n",
    "train = train_tr.join(train_id, on='TransactionID', how='left')\n",
    "test = test_tr.join(test_id, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Drop columns from train and test DataFrames\n",
    "train_X = train.drop('isFraud', 'TransactionDT', 'TransactionID')\n",
    "train_y = train.select('isFraud')\n",
    "\n",
    "test_X = test.drop('TransactionDT', 'TransactionID')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the difference between train_X and test_X column sets\n",
    "set1 = set(train_X.columns)\n",
    "set2 = set(test_X.columns)\n",
    "\n",
    "diff1 = set1 - set2\n",
    "diff2 = set2 - set1\n",
    "\n",
    "print(\"Difference between train_X and test_X columns:\", diff1)\n",
    "print(\"Difference between test_X and train_X columns:\", diff2)\n",
    "\n",
    "# Rename columns in the test_X DataFrame\n",
    "column_mapping = {\n",
    "    'id-38': 'id_38', 'id-36': 'id_36', 'id-29': 'id_29', 'id-05': 'id_05', 'id-15': 'id_15', 'id-22': 'id_22',\n",
    "    'id-01': 'id_01', 'id-31': 'id_31', 'id-33': 'id_33', 'id-20': 'id_20', 'id-28': 'id_28', 'id-37': 'id_37',\n",
    "    'id-30': 'id_30', 'id-27': 'id_27', 'id-35': 'id_35', 'id-32': 'id_32', 'id-08': 'id_08', 'id-17': 'id_17',\n",
    "    'id-19': 'id_19', 'id-21': 'id_21', 'id-13': 'id_13', 'id-04': 'id_04', 'id-06': 'id_06', 'id-09': 'id_09',\n",
    "    'id-11': 'id_11', 'id-02': 'id_02', 'id-34': 'id_34', 'id-10': 'id_10', 'id-26': 'id_26', 'id-24': 'id_24',\n",
    "    'id-25': 'id_25', 'id-07': 'id_07', 'id-14': 'id_14', 'id-18': 'id_18', 'id-03': 'id_03', 'id-12': 'id_12',\n",
    "    'id-16': 'id_16', 'id-23': 'id_23'\n",
    "}\n",
    "\n",
    "for old_col, new_col in column_mapping.items():\n",
    "    test_X = test_X.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def impute_NaN_with_mode(df):\n",
    "    mode_dict = {}\n",
    "    for column in df.columns:\n",
    "        # Get a mode value for that dataframe\n",
    "        mode_value = df.groupBy(column).agg(F.count(column).alias('count')).orderBy(F.desc('count')).collect()[0][column]\n",
    "        mode_dict[column] = mode_value\n",
    "    return df.na.fill(mode_dict)\n",
    "\n",
    "train_X = impute_NaN_with_mode(train_X)\n",
    "test_X = impute_NaN_with_mode(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "cat_cols = [\n",
    "    \"ProductCD\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"addr1\", \"addr2\",\n",
    "    \"P_emaildomain\", \"R_emaildomain\", \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\",\n",
    "    \"DeviceType\", \"DeviceInfo\", \"id_12\", \"id_13\", \"id_14\", \"id_15\", \"id_16\", \"id_17\", \"id_18\", \"id_19\",\n",
    "    \"id_20\", \"id_21\", \"id_22\", \"id_23\", \"id_24\", \"id_25\", \"id_26\", \"id_27\",\n",
    "    \"id_28\", \"id_29\", \"id_30\", \"id_31\", \"id_32\", \"id_33\", \"id_34\", \"id_35\", \"id_36\", \"id_37\", \"id_38\"\n",
    "]\n",
    "\n",
    "for col in cat_cols:\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", stringOrderType=\"alphabetAsc\")\n",
    "    \n",
    "    # Fit the StringIndexer on the combined train and test DataFrames\n",
    "    combined_df = train_X.union(test_X)\n",
    "    indexer_model = indexer.fit(combined_df)\n",
    "    \n",
    "    # Transform the train_X and test_X DataFrames\n",
    "    train_X = indexer_model.transform(train_X).drop(col).withColumnRenamed(f\"{col}_indexed\", col)\n",
    "    test_X = indexer_model.transform(test_X).drop(col).withColumnRenamed(f\"{col}_indexed\", col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for lgb, explanation in each line\n",
    "lgb_params = {\n",
    "                'objective': 'binary', # Fraud or not fraud, binary classification problem\n",
    "                'max_depth': -1, # Maximum depth is set to infinite\n",
    "                \"boosting_type\": \"gbdt\", # Gradient boosted decision tree is the one im most familiar with \n",
    "                \"metric\": 'auc', # Using area under curve for metric, optimal for binary classification, can also use binary_logloss\n",
    "                \"verbosity\": -1, # Logging all activities\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert train_X and train_y Spark DataFrames to pandas DataFrames\n",
    "train_X_pd = train_X.toPandas()\n",
    "train_y_pd = train_y.toPandas()\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "# 70/30 standard train test split\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X_pd, train_y_pd, test_size=0., random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lightgbm.plotting import *\n",
    "from matplotlib import pyplot\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_dataset = lgb.Dataset(train_X, train_y, categorical_feature = cat_cols)\n",
    "eval_dataset = lgb.Dataset(val_X, val_y, categorical_feature = cat_cols, reference = train_dataset)\n",
    "\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                train_dataset, \n",
    "                valid_sets=[train_dataset, eval_dataset]\n",
    "              )\n",
    "\n",
    "ax = plot_importance(lgb_model, max_num_features=20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming test_data is your test DataFrame without target labels\n",
    "predictions = lgb_model.predict(test_X)\n",
    "\n",
    "# Convert the predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(predictions, columns=[\"prediction\"])\n",
    "\n",
    "# Save the predictions DataFrame as a CSV file\n",
    "predictions_df.to_csv(\"submission_telkomsel_ps2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
